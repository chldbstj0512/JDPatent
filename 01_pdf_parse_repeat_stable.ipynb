{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_01.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_01.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_02.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_02.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_03.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_03.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_04.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_04.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_05.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_05.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_06.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_06.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_07.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_07.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_08.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_08.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_09.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_09.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_10.pdf\n",
      "âœ… ì™„ë£Œ: /home/ys0660/JDProject/sample/test_10.pdf\n",
      "\n",
      "âœ… CSV ì €ì¥ ì™„ë£Œ: user_patent_info_all_stable.csv\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# (1) í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "results = []\n",
    "\n",
    "# (2) test_01.pdf ~ test_10.pdf ìˆœì°¨ ì²˜ë¦¬\n",
    "for i in range(1, 11):\n",
    "    pdf_path = f\"/home/ys0660/JDProject/sample/test_{i:02d}.pdf\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"âš ï¸ íŒŒì¼ ì—†ìŒ: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸ“„ ì²˜ë¦¬ ì¤‘: {pdf_path}\")\n",
    "\n",
    "    try:\n",
    "        # (3) PDFì˜ ì• 2í˜ì´ì§€ë§Œ ì´ë¯¸ì§€ë¡œ ë³€í™˜\n",
    "        pages = convert_from_path(pdf_path, first_page=1, last_page=2)\n",
    "\n",
    "        # (4) OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        text = \"\"\n",
    "        for j, page in enumerate(pages):\n",
    "            page_text = pytesseract.image_to_string(page, lang=\"kor+eng\")\n",
    "            text += f\"\\n--- Page {j+1} ---\\n\" + page_text\n",
    "            page.close()  # ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ í•´ì œ\n",
    "        del pages\n",
    "\n",
    "        # (5) í”„ë¡¬í”„íŠ¸ (ìˆ˜ì • ê¸ˆì§€)\n",
    "        prompt = f\"\"\"\n",
    "        You are a patent information extraction assistant.\n",
    "        From the following patent text, extract the following fields and return them **only** as a valid JSON object:\n",
    "\n",
    "        - country: The country name or code (e.g., \"US\", \"KR\")\n",
    "        - date: The publication or filing date in ISO format (YYYY-MM-DD)\n",
    "        - title: The name of the invention or patent\n",
    "        - applicant: The applicant or organization that submitted the patent\n",
    "        - ipc_code: A list of IPC classification codes (e.g., [\"A61K 39/05\", \"C07K 14/195\"])\n",
    "        - naics_code: A list of estimated NAICS codes relevant to the invention's industry (e.g., [\"325412\", \"334413\"])\n",
    "        - abstract: The abstract text\n",
    "\n",
    "        ### Additional Rules:\n",
    "        1. For IPC codes:\n",
    "           - Extract from the text, then verify semantic consistency with the abstract.\n",
    "           - If invalid or irrelevant, replace with valid and relevant IPC codes (standard format required).\n",
    "        2. For NAICS codes:\n",
    "           - Infer the most relevant NAICS industry classification based on the abstract and title.\n",
    "           - Return one or more 6-digit NAICS codes that best match the inventionâ€™s domain.\n",
    "           - If uncertain, return `null`.\n",
    "\n",
    "        If some information is missing, return `null` for that field.\n",
    "\n",
    "        Patent text:\n",
    "        {text}\n",
    "        \"\"\"\n",
    "\n",
    "        # (6) GPT í˜¸ì¶œ\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You extract structured patent metadata in JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        # (7) JSON ë¸”ë¡ ì¶”ì¶œ\n",
    "        match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)\n",
    "        if not match:\n",
    "            print(f\"âŒ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = json.loads(match.group(0))\n",
    "            data[\"file_name\"] = os.path.basename(pdf_path)\n",
    "            results.append(data)\n",
    "            print(f\"âœ… ì™„ë£Œ: {pdf_path}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {pdf_path}\")\n",
    "            continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ ({pdf_path}): {e}\")\n",
    "        continue\n",
    "\n",
    "    # (8) ê° íŒŒì¼ ì²˜ë¦¬ í›„ 3ì´ˆ ëŒ€ê¸°\n",
    "    time.sleep(3)\n",
    "\n",
    "# (9) CSV ì €ì¥\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"ipc_code\"] = df[\"ipc_code\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else x)\n",
    "    df[\"naics_code\"] = df[\"naics_code\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else x)\n",
    "\n",
    "    df.to_csv(\"user_patent_info_all_stable.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"\\nâœ… CSV ì €ì¥ ì™„ë£Œ: user_patent_info_all_stable.csv\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_01.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: en\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_02.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: en\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_03.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: en\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_04.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: ko\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_05.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: ko\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_06.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: en\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_07.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: ko\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_08.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: ko\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_09.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: en\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_10.pdf\n",
      "ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: en\n",
      "âœ… CSV ì €ì¥ ì™„ë£Œ: user_patent_info_all.csv (íŒ¨í„´ê¸°ë°˜ ì–¸ì–´ê°ì§€ ì ìš©)\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "results = []\n",
    "\n",
    "def detect_patent_language(page):\n",
    "    \"\"\"íŠ¹í—ˆ ìƒë‹¨ë¶€ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì–¸ì–´ ê°ì§€\"\"\"\n",
    "    width, height = page.size\n",
    "    header_region = page.crop((0, 0, width, height * 0.40))\n",
    "    header_text = pytesseract.image_to_string(header_region, lang=\"kor+eng\").lower()\n",
    "\n",
    "    if any(kw in header_text for kw in [\"ëŒ€í•œë¯¼êµ­íŠ¹í—ˆì²­\", \"korean intellectual property\", \"KR\", \"ê³µê°œì¼ì\", \"ë“±ë¡\", \"ì¶œì›\"]):\n",
    "        return \"ko\"\n",
    "    elif any(kw in header_text for kw in [\"United States Patent\", \"United States\", \"Patent\"]):\n",
    "        return \"en\"\n",
    "    else:\n",
    "        # ê¸°ë³¸ê°’: ì˜ì–´ë¡œ\n",
    "        return \"en\"\n",
    "\n",
    "# PDF ë°˜ë³µ\n",
    "for i in range(1, 11):\n",
    "    pdf_path = f\"/home/ys0660/JDProject/sample/test_{i:02d}.pdf\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸ“„ ì²˜ë¦¬ ì¤‘: {pdf_path}\")\n",
    "\n",
    "    pages = convert_from_path(pdf_path, first_page=1, last_page=2)\n",
    "\n",
    "    # (1) ì²« í˜ì´ì§€ì—ì„œ ì–¸ì–´/êµ­ê°€ íŒë‹¨\n",
    "    patent_lang = detect_patent_language(pages[0])\n",
    "    print(f\"ğŸŒ íŠ¹í—ˆ ì–¸ì–´ íŒë‹¨: {patent_lang}\")\n",
    "\n",
    "    text = \"\"\n",
    "    custom_config = \"--psm 6\"\n",
    "\n",
    "    # (2) ì–¸ì–´ë³„ OCR ë°©ì‹\n",
    "    for j, page in enumerate(pages):\n",
    "        width, height = page.size\n",
    "\n",
    "        if patent_lang == \"ko\":\n",
    "            # âœ… í•œêµ­ì–´ â†’ ëª¨ë“  ë¶€ë¶„ 1ë‹¨ OCR (ëª…ì¹­+ìš”ì•½ í¬í•¨)\n",
    "            page_text = pytesseract.image_to_string(page, lang=\"kor+eng\", config=custom_config)\n",
    "        else:\n",
    "            # âœ… ì˜ì–´ â†’ 2ë‹¨ OCR (column-aware)\n",
    "            mid_x = width // 2\n",
    "            left_col = page.crop((0, 0, mid_x, height))\n",
    "            right_col = page.crop((mid_x, 0, width, height))\n",
    "\n",
    "            left_text = pytesseract.image_to_string(left_col, lang=\"kor+eng\", config=custom_config)\n",
    "            right_text = pytesseract.image_to_string(right_col, lang=\"kor+eng\", config=custom_config)\n",
    "            page_text = left_text.strip() + \"\\n\" + right_text.strip()\n",
    "\n",
    "        text += f\"\\n--- Page {j+1} ---\\n{page_text.strip()}\\n\"\n",
    "\n",
    "    # (3) GPT í”„ë¡¬í”„íŠ¸\n",
    "    prompt = f\"\"\"\n",
    "You are a patent information extraction assistant.\n",
    "From the following patent text, extract the following fields and return them **only** as a valid JSON object:\n",
    "\n",
    "- country: The country name or code (e.g., \"US\", \"KR\")\n",
    "- date: The **filing date** in ISO format (YYYY-MM-DD)\n",
    "- title: The title of the invention or patent\n",
    "- applicant: The applicant or organization that filed the patent\n",
    "- ipc_code: A list of IPC classification codes (e.g., [\"A61K 39/05\", \"C07K 14/195\"])\n",
    "- naics_code: A list of up to **three (3)** estimated NAICS codes relevant to the inventionâ€™s industry (e.g., [\"325412\", \"334413\", \"541715\"])\n",
    "- abstract: The full abstract text (including text continued on the next page)\n",
    "\n",
    "### Extraction Rules:\n",
    "\n",
    "1. **Filing Date (ì¶œì›ì¼ì)**:\n",
    "   - Use the field labeled **(22) PCT Filed**, **(22) Application Filed**, or similar.\n",
    "   - **Do not use (43) Publication Date** or **(45) Published** â€” these are *not* filing dates.\n",
    "   - Return in ISO format (YYYY-MM-DD). If no valid filing date exists, return `null`.\n",
    "\n",
    "2. **Applicant (ì¶œì›ì¸ / íŠ¹í—ˆê¶Œì)**:\n",
    "   - Extract from field **(73) Assignee / Applicant / Patentee**.\n",
    "   - If multiple applicants exist, return as a comma-separated string.\n",
    "\n",
    "3. **IPC Codes**:\n",
    "   - Extract all IPC classification codes **exactly as they appear** in the text (e.g., under (51) Int. Cl.).\n",
    "   - Verify that each IPC code follows valid IPC syntax (e.g., â€œA61K 39/05â€).\n",
    "   - If a code is invalid or malformed, replace it with the **closest semantically correct and valid IPC code**.\n",
    "   - Do **not invent new codes** that are not in the text.\n",
    "\n",
    "4. **NAICS Codes**:\n",
    "   - Infer the **three most relevant 6-digit NAICS codes** based on the title and abstract.\n",
    "   - Select codes representing the main industrial domains or applications.\n",
    "   - If uncertain, return `null`.\n",
    "\n",
    "5. **Abstract (ìš”ì•½ë¬¸)**:\n",
    "   - Combine all parts of the abstract, even if marked as **â€œ(continued)â€** or split across pages.\n",
    "   - Return the **entire abstract text**, preserving readability and continuity.\n",
    "\n",
    "6. **Missing Information**:\n",
    "   - If any field cannot be found, return `null` for that field.\n",
    "\n",
    "Patent text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "    # (4) GPT í˜¸ì¶œ\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You extract structured patent metadata in JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    response_text = response.choices[0].message.content.strip()\n",
    "\n",
    "    # (5) JSON íŒŒì‹±\n",
    "    match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)\n",
    "    if not match:\n",
    "        print(f\"âŒ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        data = json.loads(match.group(0))\n",
    "        data[\"file_name\"] = os.path.basename(pdf_path)\n",
    "        data[\"ocr_text\"] = text.strip()\n",
    "        results.append(data)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "# (6) CSV ì €ì¥\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"ipc_code\"] = df[\"ipc_code\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else x)\n",
    "    df[\"naics_code\"] = df[\"naics_code\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else x)\n",
    "    df.to_csv(\"user_patent_info_all.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"âœ… CSV ì €ì¥ ì™„ë£Œ: user_patent_info_all.csv (íŒ¨í„´ê¸°ë°˜ ì–¸ì–´ê°ì§€ ì ìš©)\")\n",
    "else:\n",
    "    print(\"âš ï¸ ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_01.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_02.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_03.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_04.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_05.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_06.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_07.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_08.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_09.pdf\n",
      "\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: /home/ys0660/JDProject/sample/test_10.pdf\n",
      "âœ… CSV ì €ì¥ ì™„ë£Œ: user_patent_info_all_v5.csv (pdfplumber ê¸°ë°˜)\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "results = []\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ê¸°ë°˜ PDF â†’ pdfplumberë¡œ ì¶”ì¶œ, ë¹„ì–´ ìˆìœ¼ë©´ OCR fallback\"\"\"\n",
    "    text = \"\"\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for i, page in enumerate(pdf.pages[:2]):  # ì• 2í˜ì´ì§€\n",
    "                extracted = page.extract_text()\n",
    "                if extracted and extracted.strip():\n",
    "                    text += f\"\\n--- Page {i+1} (text) ---\\n\" + extracted\n",
    "                else:\n",
    "                    # OCR fallback (ì´ë¯¸ì§€í™” í›„ pytesseract)\n",
    "                    image = page.to_image(resolution=300).original\n",
    "                    ocr_text = pytesseract.image_to_string(image, lang=\"kor+eng\")\n",
    "                    text += f\"\\n--- Page {i+1} (ocr) ---\\n\" + ocr_text\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ pdfplumber ì‹¤íŒ¨, OCR ì „ì²´ ì²˜ë¦¬ë¡œ ì „í™˜: {e}\")\n",
    "        pages = convert_from_path(pdf_path, first_page=1, last_page=2)\n",
    "        for j, page in enumerate(pages):\n",
    "            ocr_text = pytesseract.image_to_string(page, lang=\"kor+eng\")\n",
    "            text += f\"\\n--- Page {j+1} (ocr only) ---\\n\" + ocr_text\n",
    "    return text.strip()\n",
    "\n",
    "# PDF ë°˜ë³µ\n",
    "for i in range(1, 11):\n",
    "    pdf_path = f\"/home/ys0660/JDProject/sample/test_{i:02d}.pdf\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸ“„ ì²˜ë¦¬ ì¤‘: {pdf_path}\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # GPT í”„ë¡¬í”„íŠ¸\n",
    "    prompt = f\"\"\"\n",
    "You are a patent information extraction assistant.\n",
    "From the following patent text, extract the following fields and return them **only** as a valid JSON object:\n",
    "\n",
    "- country: The country name or code (e.g., \"US\", \"KR\")\n",
    "- date: The **filing date** in ISO format (YYYY-MM-DD)\n",
    "- title: The title of the invention or patent\n",
    "- applicant: The applicant or organization that filed the patent\n",
    "- ipc_code: A list of IPC classification codes (e.g., [\"A61K 39/05\", \"C07K 14/195\"])\n",
    "- naics_code: A list of up to **three (3)** estimated NAICS codes relevant to the inventionâ€™s industry (e.g., [\"325412\", \"334413\", \"541715\"])\n",
    "- abstract: The full abstract text (including text continued on the next page)\n",
    "\n",
    "### Extraction Rules:\n",
    "\n",
    "1. **Filing Date (ì¶œì›ì¼ì)**:\n",
    "   - Use the field labeled **(22) PCT Filed**, **(22) Application Filed**, or similar.\n",
    "   - **Do not use (43) Publication Date** or **(45) Published** â€” these are *not* filing dates.\n",
    "   - Return in ISO format (YYYY-MM-DD). If no valid filing date exists, return `null`.\n",
    "\n",
    "2. **Applicant (ì¶œì›ì¸ / íŠ¹í—ˆê¶Œì)**:\n",
    "   - Extract from field **(73) Assignee / Applicant / Patentee**.\n",
    "   - If multiple applicants exist, return as a comma-separated string.\n",
    "\n",
    "3. **IPC Codes**:\n",
    "   - Extract all IPC classification codes **exactly as they appear** in the text (e.g., under (51) Int. Cl.).\n",
    "   - Verify that each IPC code follows valid IPC syntax (e.g., â€œA61K 39/05â€).\n",
    "   - If a code is invalid or malformed, replace it with the **closest semantically correct and valid IPC code**.\n",
    "   - Do **not invent new codes** that are not in the text.\n",
    "\n",
    "4. **NAICS Codes**:\n",
    "   - Infer the **three most relevant 6-digit NAICS codes** based on the title and abstract.\n",
    "   - Select codes representing the main industrial domains or applications.\n",
    "   - If uncertain, return `null`.\n",
    "\n",
    "5. **Abstract (ìš”ì•½ë¬¸)**:\n",
    "   - Combine all parts of the abstract, even if marked as **â€œ(continued)â€** or split across pages.\n",
    "   - Return the **entire abstract text**, preserving readability and continuity.\n",
    "\n",
    "6. **Missing Information**:\n",
    "   - If any field cannot be found, return `null` for that field.\n",
    "\n",
    "Patent text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "    # GPT í˜¸ì¶œ\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You extract structured patent metadata in JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    response_text = response.choices[0].message.content.strip()\n",
    "\n",
    "    # JSON íŒŒì‹±\n",
    "    match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)\n",
    "    if not match:\n",
    "        print(f\"âŒ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        data = json.loads(match.group(0))\n",
    "        data[\"file_name\"] = os.path.basename(pdf_path)\n",
    "        data[\"ocr_text\"] = text\n",
    "        results.append(data)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "# CSV ì €ì¥\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"ipc_code\"] = df[\"ipc_code\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else x)\n",
    "    df[\"naics_code\"] = df[\"naics_code\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else x)\n",
    "    df.to_csv(\"user_patent_info_all_v5.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"âœ… CSV ì €ì¥ ì™„ë£Œ: user_patent_info_all_v5.csv (pdfplumber ê¸°ë°˜)\")\n",
    "else:\n",
    "    print(\"âš ï¸ ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ys0660",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
